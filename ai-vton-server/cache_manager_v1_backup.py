"""
2Îã®Í≥Ñ Ï∫êÏã± ÏãúÏä§ÌÖú (L1: Memory, L2: SSD)
LRU + TTL ÏïåÍ≥†Î¶¨Ï¶ò

Íµ¨Ï°∞:
- L1 (Memory): ÏµúÍ∑º ÏÇ¨Ïö©Ìïú NÎ™ÖÏùò ÏÇ¨Ïö©Ïûê Îç∞Ïù¥ÌÑ∞ (Îπ†Î¶Ñ, Ïö©Îüâ ÏûëÏùå)
- L2 (SSD /opt/dlami/nvme): S3 Îã§Ïö¥Î°úÎìú ÏôÑÏ∂© (Ï§ëÍ∞Ñ ÏÜçÎèÑ, Ïö©Îüâ ÌÅº)

Ï∫êÏã± ÏïåÍ≥†Î¶¨Ï¶ò: LRU (Least Recently Used) + TTL (Time To Live)
- LRU: ÏµúÍ∑º ÏÇ¨Ïö©ÌïòÏßÄ ÏïäÏùÄ Îç∞Ïù¥ÌÑ∞Î∂ÄÌÑ∞ Ï†úÍ±∞
- TTL: ÏùºÏ†ï ÏãúÍ∞Ñ ÌõÑ ÏûêÎèô ÎßåÎ£å (Ï†ÑÏã† ÏÇ¨ÏßÑ Î≥ÄÍ≤Ω ÎåÄÏùë)
"""

import os
import time
import pickle
import shutil
import logging
from pathlib import Path
from collections import OrderedDict
from typing import Optional, Dict, Any, Tuple
from PIL import Image
import torch
import io
import base64
from dataclasses import dataclass
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)


@dataclass
class CacheEntry:
    """Ï∫êÏãú ÏóîÌä∏Î¶¨ Î©îÌÉÄÎç∞Ïù¥ÌÑ∞"""
    key: str
    data: Any  # PIL Image, Tensor, etc.
    size_bytes: int
    created_at: float
    accessed_at: float
    access_count: int


class TwoLevelCache:
    """
    2Îã®Í≥Ñ Ï∫êÏã± ÏãúÏä§ÌÖú

    L1 (Memory): OrderedDict Í∏∞Î∞ò LRU (Îπ†Î¶Ñ)
    L2 (SSD): ÌååÏùº ÏãúÏä§ÌÖú Í∏∞Î∞ò (Ï§ëÍ∞Ñ)
    L3 (S3): ÏõêÎ≥∏ ÏÜåÏä§ (ÎäêÎ¶º)
    """

    def __init__(
        self,
        ssd_root: str = "/opt/dlami/nvme/vton-cache",
        l1_max_users: int = 10,  # Î©îÎ™®Î¶¨Ïóê ÏµúÎåÄ NÎ™ÖÏùò ÏÇ¨Ïö©Ïûê Îç∞Ïù¥ÌÑ∞
        l1_max_garments: int = 100,  # Î©îÎ™®Î¶¨Ïóê ÏµúÎåÄ NÍ∞úÏùò Ïò∑ Îç∞Ïù¥ÌÑ∞
        ttl_hours: int = 24,  # 24ÏãúÍ∞Ñ ÌõÑ ÎßåÎ£å
    ):
        self.ssd_root = Path(ssd_root)
        self.ssd_root.mkdir(parents=True, exist_ok=True)

        # L1 Ï∫êÏãú (Memory) - categoryÎ≥Ñ Î∂ÑÎ¶¨
        self.l1_human_upper: OrderedDict[str, CacheEntry] = OrderedDict()
        self.l1_human_lower: OrderedDict[str, CacheEntry] = OrderedDict()
        self.l1_human_dresses: OrderedDict[str, CacheEntry] = OrderedDict()
        self.l1_garment: OrderedDict[str, CacheEntry] = OrderedDict()
        self.l1_text: OrderedDict[str, CacheEntry] = OrderedDict()

        # Ïö©Îüâ Ï†úÌïú
        self.l1_max_users = l1_max_users
        self.l1_max_garments = l1_max_garments

        # TTL ÏÑ§Ï†ï
        self.ttl_seconds = ttl_hours * 3600

        # ÌÜµÍ≥Ñ
        self.stats = {
            "l1_hits": 0,
            "l2_hits": 0,
            "l3_hits": 0,  # S3 Îã§Ïö¥Î°úÎìú
            "evictions": 0,
        }

        logger.info(f"‚úÖ 2-Level Cache initialized:")
        logger.info(f"   L1 (Memory): max {l1_max_users} users, {l1_max_garments} garments")
        logger.info(f"   L2 (SSD): {self.ssd_root}")
        logger.info(f"   TTL: {ttl_hours} hours")

    def _is_expired(self, entry: CacheEntry) -> bool:
        """TTL Ï≤¥ÌÅ¨"""
        age = time.time() - entry.created_at
        return age > self.ttl_seconds

    def _evict_lru(self, cache: OrderedDict, max_size: int):
        """LRU Î∞©ÏãùÏúºÎ°ú Ïò§ÎûòÎêú Ìï≠Î™© Ï†úÍ±∞"""
        while len(cache) > max_size:
            key, entry = cache.popitem(last=False)  # FIFO (Í∞ÄÏû• Ïò§ÎûòÎêú Ìï≠Î™©)
            logger.info(f"üóëÔ∏è  Evicted from L1: {key} (size: {entry.size_bytes} bytes)")
            self.stats["evictions"] += 1

    def _get_ssd_path(self, cache_type: str, key: str, filename: str) -> Path:
        """L2 (SSD) ÌååÏùº Í≤ΩÎ°ú ÏÉùÏÑ±"""
        return self.ssd_root / cache_type / key / filename

    def _save_to_ssd(self, cache_type: str, key: str, data: Dict[str, Any]):
        """L2 (SSD)Ïóê Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•"""
        base_path = self.ssd_root / cache_type / key
        base_path.mkdir(parents=True, exist_ok=True)

        for name, value in data.items():
            file_path = base_path / f"{name}.pkl"

            try:
                with open(file_path, "wb") as f:
                    if isinstance(value, Image.Image):
                        # PIL ImageÎäî PNGÎ°ú Ï†ÄÏû•
                        img_path = base_path / f"{name}.png"
                        value.save(img_path, "PNG")
                    elif isinstance(value, torch.Tensor):
                        # TensorÎäî pickleÎ°ú Ï†ÄÏû• (CPUÎ°ú Ïù¥Îèô)
                        pickle.dump(value.cpu(), f)
                    else:
                        # Í∏∞ÌÉÄÎäî pickle
                        pickle.dump(value, f)

            except Exception as e:
                logger.error(f"‚ùå Failed to save {name} to SSD: {e}")

    def _load_from_ssd(self, cache_type: str, key: str) -> Optional[Dict[str, Any]]:
        """L2 (SSD)ÏóêÏÑú Îç∞Ïù¥ÌÑ∞ Î°úÎìú"""
        base_path = self.ssd_root / cache_type / key

        if not base_path.exists():
            return None

        try:
            data = {}

            # PNG ÌååÏùº Î°úÎìú
            for png_file in base_path.glob("*.png"):
                name = png_file.stem
                data[name] = Image.open(png_file)

            # PKL ÌååÏùº Î°úÎìú
            for pkl_file in base_path.glob("*.pkl"):
                name = pkl_file.stem
                with open(pkl_file, "rb") as f:
                    data[name] = pickle.load(f)

            return data if data else None

        except Exception as e:
            logger.error(f"‚ùå Failed to load from SSD: {e}")
            return None

    def get_human_cache(
        self,
        user_id: str,
        category: str = "upper_body"
    ) -> Optional[Dict[str, Any]]:
        """
        Human Ï∫êÏãú Ï°∞Ìöå (L1 ‚Üí L2 ‚Üí L3)

        Returns:
            {
                'human_img': PIL.Image,
                'mask': PIL.Image,
                'mask_gray': PIL.Image,
                'pose_tensor': torch.Tensor
            }
        """
        # categoryÏóê Îî∞Îùº L1 Ï∫êÏãú ÏÑ†ÌÉù
        if category == "upper_body":
            l1_cache = self.l1_human_upper
        elif category == "lower_body":
            l1_cache = self.l1_human_lower
        else:  # dresses
            l1_cache = self.l1_human_dresses

        # L1 Ï≤¥ÌÅ¨
        if user_id in l1_cache:
            entry = l1_cache[user_id]

            # TTL Ï≤¥ÌÅ¨
            if self._is_expired(entry):
                logger.info(f"‚è∞ L1 cache expired for user {user_id} ({category})")
                del l1_cache[user_id]
            else:
                # Cache HIT
                entry.accessed_at = time.time()
                entry.access_count += 1
                l1_cache.move_to_end(user_id)  # LRU ÏóÖÎç∞Ïù¥Ìä∏
                self.stats["l1_hits"] += 1
                logger.info(f"‚úÖ L1 HIT: user {user_id} ({category})")
                return entry.data

        # L2 Ï≤¥ÌÅ¨ (SSD)
        l2_data = self._load_from_ssd(f"human_{category}", user_id)
        if l2_data:
            self.stats["l2_hits"] += 1
            logger.info(f"‚úÖ L2 HIT: user {user_id} ({category}) - loading to L1")

            # L1Ïóê Ï∫êÏãú
            self._put_l1_human(user_id, l2_data, category)
            return l2_data

        # L3 (S3) - callerÍ∞Ä Ï≤òÎ¶¨
        logger.info(f"‚ùå Cache MISS: user {user_id} ({category})")
        return None

    def put_human_cache(
        self,
        user_id: str,
        data: Dict[str, Any],
        category: str = "upper_body"
    ):
        """Human Ï∫êÏãú Ï†ÄÏû• (L1 + L2)"""
        # L1Ïóê Ï†ÄÏû•
        self._put_l1_human(user_id, data, category)

        # L2 (SSD)Ïóê Ï†ÄÏû•
        self._save_to_ssd(f"human_{category}", user_id, data)
        logger.info(f"üíæ Cached human {user_id} ({category}) to L1 + L2")

    def _put_l1_human(self, user_id: str, data: Dict[str, Any], category: str):
        """L1 Human Ï∫êÏãúÏóê Ï†ÄÏû• (internal)"""
        # categoryÏóê Îî∞Îùº L1 Ï∫êÏãú ÏÑ†ÌÉù
        if category == "upper_body":
            l1_cache = self.l1_human_upper
        elif category == "lower_body":
            l1_cache = self.l1_human_lower
        else:  # dresses
            l1_cache = self.l1_human_dresses

        # ÌÅ¨Í∏∞ Í≥ÑÏÇ∞ (ÎåÄÎûµÏ†Å)
        size_bytes = sum(
            self._estimate_size(v) for v in data.values()
        )

        entry = CacheEntry(
            key=user_id,
            data=data,
            size_bytes=size_bytes,
            created_at=time.time(),
            accessed_at=time.time(),
            access_count=1,
        )

        l1_cache[user_id] = entry
        l1_cache.move_to_end(user_id)  # MRU

        # LRU eviction
        self._evict_lru(l1_cache, self.l1_max_users)

    def get_garment_cache(self, clothing_id: str) -> Optional[Dict[str, Any]]:
        """
        Garment Ï∫êÏãú Ï°∞Ìöå

        Returns:
            {
                'garm_img': PIL.Image,
                'garm_tensor': torch.Tensor
            }
        """
        # L1 Ï≤¥ÌÅ¨
        if clothing_id in self.l1_garment:
            entry = self.l1_garment[clothing_id]

            if self._is_expired(entry):
                del self.l1_garment[clothing_id]
            else:
                entry.accessed_at = time.time()
                entry.access_count += 1
                self.l1_garment.move_to_end(clothing_id)
                self.stats["l1_hits"] += 1
                logger.info(f"‚úÖ L1 HIT: garment {clothing_id}")
                return entry.data

        # L2 Ï≤¥ÌÅ¨
        l2_data = self._load_from_ssd("garment", clothing_id)
        if l2_data:
            self.stats["l2_hits"] += 1
            logger.info(f"‚úÖ L2 HIT: garment {clothing_id}")
            self._put_l1_garment(clothing_id, l2_data)
            return l2_data

        return None

    def put_garment_cache(self, clothing_id: str, data: Dict[str, Any]):
        """Garment Ï∫êÏãú Ï†ÄÏû•"""
        self._put_l1_garment(clothing_id, data)
        self._save_to_ssd("garment", clothing_id, data)
        logger.info(f"üíæ Cached garment {clothing_id} to L1 + L2")

    def _put_l1_garment(self, clothing_id: str, data: Dict[str, Any]):
        """L1 Garment Ï∫êÏãúÏóê Ï†ÄÏû•"""
        size_bytes = sum(self._estimate_size(v) for v in data.values())

        entry = CacheEntry(
            key=clothing_id,
            data=data,
            size_bytes=size_bytes,
            created_at=time.time(),
            accessed_at=time.time(),
            access_count=1,
        )

        self.l1_garment[clothing_id] = entry
        self.l1_garment.move_to_end(clothing_id)
        self._evict_lru(self.l1_garment, self.l1_max_garments)

    def get_text_cache(self, clothing_id: str) -> Optional[Dict[str, Any]]:
        """Text Ï∫êÏãú Ï°∞Ìöå"""
        # L1 Ï≤¥ÌÅ¨
        if clothing_id in self.l1_text:
            entry = self.l1_text[clothing_id]

            if self._is_expired(entry):
                del self.l1_text[clothing_id]
            else:
                entry.accessed_at = time.time()
                entry.access_count += 1
                self.l1_text.move_to_end(clothing_id)
                self.stats["l1_hits"] += 1
                return entry.data

        # L2 Ï≤¥ÌÅ¨
        l2_data = self._load_from_ssd("text", clothing_id)
        if l2_data:
            self.stats["l2_hits"] += 1
            self._put_l1_text(clothing_id, l2_data)
            return l2_data

        return None

    def put_text_cache(self, clothing_id: str, data: Dict[str, Any]):
        """Text Ï∫êÏãú Ï†ÄÏû•"""
        self._put_l1_text(clothing_id, data)
        self._save_to_ssd("text", clothing_id, data)

    def _put_l1_text(self, clothing_id: str, data: Dict[str, Any]):
        """L1 Text Ï∫êÏãúÏóê Ï†ÄÏû•"""
        size_bytes = sum(self._estimate_size(v) for v in data.values())

        entry = CacheEntry(
            key=clothing_id,
            data=data,
            size_bytes=size_bytes,
            created_at=time.time(),
            accessed_at=time.time(),
            access_count=1,
        )

        self.l1_text[clothing_id] = entry
        self.l1_text.move_to_end(clothing_id)
        self._evict_lru(self.l1_text, self.l1_max_garments)

    def clear_user_cache(self, user_id: str):
        """ÌäπÏ†ï ÏÇ¨Ïö©ÏûêÏùò Î™®Îì† Ï∫êÏãú ÏÇ≠Ï†ú"""
        # L1 ÏÇ≠Ï†ú
        if user_id in self.l1_human_upper:
            del self.l1_human_upper[user_id]
        if user_id in self.l1_human_lower:
            del self.l1_human_lower[user_id]
        if user_id in self.l1_human_dresses:
            del self.l1_human_dresses[user_id]

        # L2 ÏÇ≠Ï†ú
        for category in ["upper_body", "lower_body", "dresses"]:
            ssd_path = self.ssd_root / f"human_{category}" / user_id
            if ssd_path.exists():
                shutil.rmtree(ssd_path)

        logger.info(f"üóëÔ∏è  Cleared all cache for user {user_id}")

    def clear_garment_cache(self, clothing_id: str):
        """ÌäπÏ†ï Ïò∑Ïùò Ï∫êÏãú ÏÇ≠Ï†ú"""
        if clothing_id in self.l1_garment:
            del self.l1_garment[clothing_id]
        if clothing_id in self.l1_text:
            del self.l1_text[clothing_id]

        for cache_type in ["garment", "text"]:
            ssd_path = self.ssd_root / cache_type / clothing_id
            if ssd_path.exists():
                shutil.rmtree(ssd_path)

    def get_stats(self) -> Dict:
        """Ï∫êÏãú ÌÜµÍ≥Ñ Î∞òÌôò"""
        total_requests = (
            self.stats["l1_hits"] +
            self.stats["l2_hits"] +
            self.stats["l3_hits"]
        )

        l1_hit_rate = (
            self.stats["l1_hits"] / total_requests * 100
            if total_requests > 0 else 0
        )
        l2_hit_rate = (
            self.stats["l2_hits"] / total_requests * 100
            if total_requests > 0 else 0
        )

        return {
            **self.stats,
            "total_requests": total_requests,
            "l1_hit_rate": round(l1_hit_rate, 2),
            "l2_hit_rate": round(l2_hit_rate, 2),
            "l1_human_upper_count": len(self.l1_human_upper),
            "l1_human_lower_count": len(self.l1_human_lower),
            "l1_human_dresses_count": len(self.l1_human_dresses),
            "l1_garment_count": len(self.l1_garment),
            "l1_text_count": len(self.l1_text),
        }

    @staticmethod
    def _estimate_size(obj: Any) -> int:
        """Í∞ùÏ≤¥ ÌÅ¨Í∏∞ Ï∂îÏ†ï (bytes)"""
        if isinstance(obj, torch.Tensor):
            return obj.element_size() * obj.nelement()
        elif isinstance(obj, Image.Image):
            return obj.width * obj.height * 3  # RGB Í∞ÄÏ†ï
        else:
            return 1024  # Í∏∞Î≥∏Í∞í 1KB
