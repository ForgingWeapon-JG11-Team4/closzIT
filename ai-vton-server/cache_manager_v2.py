"""
ìƒìš© ì„œë¹„ìŠ¤ìš© 2ë‹¨ê³„ ìºì‹± ì‹œìŠ¤í…œ (Production-Ready)

ê°œì„  ì‚¬í•­:
1. ë™ì‹œì„± ì œì–´ (asyncio.Lock)
2. Cache Stampede ë°©ì§€ (Single Flight)
3. Adaptive TTL (ì‚¬ìš© ë¹ˆë„ì— ë”°ë¼ TTL ì—°ì¥)
4. ì •í™•í•œ ë©”ëª¨ë¦¬ ì¶”ì • (sys.getsizeof)
5. L2 ë””ìŠ¤í¬ ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ë° ìë™ ì •ë¦¬
6. ë°±ê·¸ë¼ìš´ë“œ ìºì‹œ ì›Œë°
"""

import os
import sys
import time
import pickle
import shutil
import logging
import asyncio
from pathlib import Path
from collections import OrderedDict
from typing import Optional, Dict, Any, Tuple, Set
from PIL import Image
import torch
import io
import base64
from dataclasses import dataclass, field
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)


@dataclass
class CacheEntry:
    """ìºì‹œ ì—”íŠ¸ë¦¬ ë©”íƒ€ë°ì´í„°"""
    key: str
    data: Any
    size_bytes: int
    created_at: float
    accessed_at: float
    access_count: int
    # Adaptive TTL: ìì£¼ ì‚¬ìš©í•˜ë©´ TTL ì—°ì¥
    base_ttl: float = 24 * 3600  # 24ì‹œê°„

    @property
    def effective_ttl(self) -> float:
        """ì‚¬ìš© ë¹ˆë„ì— ë”°ë¼ TTL ì—°ì¥"""
        # 10íšŒ ì´ìƒ ì ‘ê·¼ ì‹œ TTL 2ë°°
        if self.access_count >= 10:
            return self.base_ttl * 2
        # 50íšŒ ì´ìƒ ì ‘ê·¼ ì‹œ TTL 4ë°° (ìµœëŒ€ 4ì¼)
        elif self.access_count >= 50:
            return self.base_ttl * 4
        return self.base_ttl


class TwoLevelCacheV2:
    """
    ìƒìš© ì„œë¹„ìŠ¤ìš© 2ë‹¨ê³„ ìºì‹± ì‹œìŠ¤í…œ

    ê°œì„  ì‚¬í•­:
    - ë™ì‹œì„± ì œì–´ (Lock)
    - Cache Stampede ë°©ì§€
    - Adaptive TTL
    - ë””ìŠ¤í¬ ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
    """

    def __init__(
        self,
        ssd_root: str = "/opt/dlami/nvme/vton-cache",
        l1_max_users: int = 10,
        l1_max_garments: int = 100,
        ttl_hours: int = 24,
        max_disk_usage_gb: float = 50.0,  # L2 ìµœëŒ€ 50GB
    ):
        self.ssd_root = Path(ssd_root)
        self.ssd_root.mkdir(parents=True, exist_ok=True)

        # L1 ìºì‹œ (Memory)
        self.l1_human_upper: OrderedDict[str, CacheEntry] = OrderedDict()
        self.l1_human_lower: OrderedDict[str, CacheEntry] = OrderedDict()
        self.l1_human_dresses: OrderedDict[str, CacheEntry] = OrderedDict()
        self.l1_garment: OrderedDict[str, CacheEntry] = OrderedDict()
        self.l1_text: OrderedDict[str, CacheEntry] = OrderedDict()

        # ë™ì‹œì„± ì œì–´ (Cache Stampede ë°©ì§€)
        self._locks: Dict[str, asyncio.Lock] = {}
        self._loading: Set[str] = set()  # í˜„ì¬ ë¡œë”© ì¤‘ì¸ í‚¤

        # ìš©ëŸ‰ ì œí•œ
        self.l1_max_users = l1_max_users
        self.l1_max_garments = l1_max_garments
        self.ttl_seconds = ttl_hours * 3600
        self.max_disk_bytes = int(max_disk_usage_gb * 1024 * 1024 * 1024)

        # í†µê³„
        self.stats = {
            "l1_hits": 0,
            "l2_hits": 0,
            "l3_hits": 0,
            "evictions": 0,
            "stampede_prevented": 0,  # Cache Stampede ë°©ì§€ íšŸìˆ˜
        }

        logger.info(f"âœ… Production 2-Level Cache initialized:")
        logger.info(f"   L1 (Memory): max {l1_max_users} users, {l1_max_garments} garments")
        logger.info(f"   L2 (SSD): {self.ssd_root} (max {max_disk_usage_gb}GB)")
        logger.info(f"   Base TTL: {ttl_hours} hours (adaptive)")
        logger.info(f"   Features: Lock, Stampede Prevention, Adaptive TTL")

    def _get_lock(self, key: str) -> asyncio.Lock:
        """í‚¤ë³„ Lock íšë“ (ë™ì‹œì„± ì œì–´)"""
        if key not in self._locks:
            self._locks[key] = asyncio.Lock()
        return self._locks[key]

    def _is_expired(self, entry: CacheEntry) -> bool:
        """Adaptive TTL ì²´í¬"""
        age = time.time() - entry.created_at
        return age > entry.effective_ttl

    def _evict_lru(self, cache: OrderedDict, max_size: int):
        """LRU ë°©ì‹ìœ¼ë¡œ ì˜¤ë˜ëœ í•­ëª© ì œê±°"""
        while len(cache) > max_size:
            key, entry = cache.popitem(last=False)
            logger.info(
                f"ğŸ—‘ï¸  Evicted from L1: {key} "
                f"(size: {entry.size_bytes} bytes, "
                f"accessed: {entry.access_count} times)"
            )
            self.stats["evictions"] += 1

    def _get_ssd_path(self, cache_type: str, key: str, filename: str) -> Path:
        """L2 (SSD) íŒŒì¼ ê²½ë¡œ ìƒì„±"""
        return self.ssd_root / cache_type / key / filename

    def _check_disk_space(self):
        """L2 ë””ìŠ¤í¬ ìš©ëŸ‰ ì²´í¬ ë° ì •ë¦¬"""
        try:
            # í˜„ì¬ ì‚¬ìš©ëŸ‰ ê³„ì‚°
            total_size = sum(
                f.stat().st_size
                for f in self.ssd_root.rglob('*')
                if f.is_file()
            )

            if total_size > self.max_disk_bytes:
                logger.warning(
                    f"âš ï¸  L2 disk usage exceeds limit: "
                    f"{total_size / 1024 / 1024 / 1024:.2f}GB / "
                    f"{self.max_disk_bytes / 1024 / 1024 / 1024:.2f}GB"
                )
                # ê°€ì¥ ì˜¤ë˜ëœ íŒŒì¼ë¶€í„° ì‚­ì œ
                self._cleanup_old_files()

        except Exception as e:
            logger.error(f"âŒ Disk space check failed: {e}")

    def _cleanup_old_files(self):
        """L2ì—ì„œ ì˜¤ë˜ëœ íŒŒì¼ ì‚­ì œ"""
        try:
            # ëª¨ë“  íŒŒì¼ì„ ìˆ˜ì • ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            files = sorted(
                self.ssd_root.rglob('*'),
                key=lambda f: f.stat().st_mtime if f.is_file() else 0
            )

            # 50% ìš©ëŸ‰ê¹Œì§€ ì‚­ì œ
            target_size = self.max_disk_bytes * 0.5
            current_size = sum(f.stat().st_size for f in files if f.is_file())

            for file in files:
                if not file.is_file():
                    continue

                if current_size <= target_size:
                    break

                file_size = file.stat().st_size
                file.unlink()
                current_size -= file_size
                logger.info(f"ğŸ—‘ï¸  Deleted old L2 file: {file}")

        except Exception as e:
            logger.error(f"âŒ Cleanup failed: {e}")

    def _save_to_ssd(self, cache_type: str, key: str, data: Dict[str, Any]):
        """L2 (SSD)ì— ë°ì´í„° ì €ì¥ + ë””ìŠ¤í¬ ì²´í¬"""
        base_path = self.ssd_root / cache_type / key
        base_path.mkdir(parents=True, exist_ok=True)

        for name, value in data.items():
            try:
                if isinstance(value, Image.Image):
                    img_path = base_path / f"{name}.png"
                    value.save(img_path, "PNG", optimize=True)
                elif isinstance(value, torch.Tensor):
                    pkl_path = base_path / f"{name}.pkl"
                    with open(pkl_path, "wb") as f:
                        pickle.dump(value.cpu(), f, protocol=pickle.HIGHEST_PROTOCOL)
                else:
                    pkl_path = base_path / f"{name}.pkl"
                    with open(pkl_path, "wb") as f:
                        pickle.dump(value, f, protocol=pickle.HIGHEST_PROTOCOL)

            except Exception as e:
                logger.error(f"âŒ Failed to save {name} to SSD: {e}")

        # ë””ìŠ¤í¬ ìš©ëŸ‰ ì²´í¬ (ë°±ê·¸ë¼ìš´ë“œë¡œ ì‹¤í–‰)
        try:
            self._check_disk_space()
        except Exception as e:
            logger.error(f"âš ï¸  Disk check failed: {e}")

    def _load_from_ssd(self, cache_type: str, key: str) -> Optional[Dict[str, Any]]:
        """L2 (SSD)ì—ì„œ ë°ì´í„° ë¡œë“œ"""
        base_path = self.ssd_root / cache_type / key

        if not base_path.exists():
            return None

        try:
            data = {}

            # PNG íŒŒì¼ ë¡œë“œ
            for png_file in base_path.glob("*.png"):
                name = png_file.stem
                data[name] = Image.open(png_file)

            # PKL íŒŒì¼ ë¡œë“œ
            for pkl_file in base_path.glob("*.pkl"):
                name = pkl_file.stem
                with open(pkl_file, "rb") as f:
                    data[name] = pickle.load(f)

            return data if data else None

        except Exception as e:
            logger.error(f"âŒ Failed to load from SSD: {e}")
            return None

    async def get_human_cache(
        self,
        user_id: str,
        category: str = "upper_body"
    ) -> Optional[Dict[str, Any]]:
        """
        Human ìºì‹œ ì¡°íšŒ (ë™ì‹œì„± ì•ˆì „)

        Cache Stampede ë°©ì§€:
        - ë™ì¼í•œ í‚¤ì— ëŒ€í•´ ì—¬ëŸ¬ ìš”ì²­ì´ ë™ì‹œì— ì˜¤ë©´
        - ì²« ë²ˆì§¸ ìš”ì²­ë§Œ S3/L2ì—ì„œ ë¡œë“œí•˜ê³ 
        - ë‚˜ë¨¸ì§€ëŠ” ëŒ€ê¸°í–ˆë‹¤ê°€ ë¡œë“œëœ ê²°ê³¼ ì‚¬ìš©
        """
        # categoryì— ë”°ë¼ L1 ìºì‹œ ì„ íƒ
        if category == "upper_body":
            l1_cache = self.l1_human_upper
        elif category == "lower_body":
            l1_cache = self.l1_human_lower
        else:
            l1_cache = self.l1_human_dresses

        cache_key = f"human_{category}_{user_id}"

        # L1 ì²´í¬ (Lock ë¶ˆí•„ìš”, ì½ê¸°ë§Œ í•¨)
        if user_id in l1_cache:
            entry = l1_cache[user_id]

            # Adaptive TTL ì²´í¬
            if self._is_expired(entry):
                logger.info(f"â° L1 cache expired for user {user_id} ({category})")
                del l1_cache[user_id]
            else:
                # Cache HIT
                entry.accessed_at = time.time()
                entry.access_count += 1
                l1_cache.move_to_end(user_id)
                self.stats["l1_hits"] += 1
                logger.info(
                    f"âœ… L1 HIT: user {user_id} ({category}) "
                    f"[accessed: {entry.access_count} times]"
                )
                return entry.data

        # Cache Stampede ë°©ì§€: ì´ë¯¸ ë¡œë”© ì¤‘ì´ë©´ ëŒ€ê¸°
        if cache_key in self._loading:
            self.stats["stampede_prevented"] += 1
            logger.info(f"â³ Waiting for ongoing load: {cache_key}")

            # ë¡œë”©ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸° (ìµœëŒ€ 30ì´ˆ)
            for _ in range(60):  # 0.5ì´ˆ * 60 = 30ì´ˆ
                await asyncio.sleep(0.5)
                if cache_key not in self._loading:
                    # ë¡œë”© ì™„ë£Œ, L1ì—ì„œ ë‹¤ì‹œ ì¡°íšŒ
                    if user_id in l1_cache:
                        return l1_cache[user_id].data
                    break

        # Lock íšë“ (ë™ì‹œì„± ì œì–´)
        lock = self._get_lock(cache_key)
        async with lock:
            # Double-check: Lock ëŒ€ê¸° ì¤‘ì— ë‹¤ë¥¸ ìŠ¤ë ˆë“œê°€ ë¡œë“œí–ˆì„ ìˆ˜ ìˆìŒ
            if user_id in l1_cache:
                return l1_cache[user_id].data

            # ë¡œë”© ì‹œì‘ í‘œì‹œ
            self._loading.add(cache_key)

            try:
                # L2 ì²´í¬ (SSD)
                l2_data = await asyncio.to_thread(
                    self._load_from_ssd, f"human_{category}", user_id
                )

                if l2_data:
                    self.stats["l2_hits"] += 1
                    logger.info(f"âœ… L2 HIT: user {user_id} ({category})")
                    self._put_l1_human(user_id, l2_data, category)
                    return l2_data

                # L3 (S3) - callerê°€ ì²˜ë¦¬
                logger.info(f"âŒ Cache MISS: user {user_id} ({category})")
                return None

            finally:
                # ë¡œë”© ì™„ë£Œ í‘œì‹œ
                self._loading.discard(cache_key)

    def put_human_cache(
        self,
        user_id: str,
        data: Dict[str, Any],
        category: str = "upper_body"
    ):
        """Human ìºì‹œ ì €ì¥ (L1 + L2)"""
        # L1ì— ì €ì¥
        self._put_l1_human(user_id, data, category)

        # L2 (SSD)ì— ì €ì¥ (ë°±ê·¸ë¼ìš´ë“œ)
        try:
            self._save_to_ssd(f"human_{category}", user_id, data)
            logger.info(f"ğŸ’¾ Cached human {user_id} ({category}) to L1 + L2")
        except Exception as e:
            logger.error(f"âŒ Failed to save to L2: {e}")

    def _put_l1_human(self, user_id: str, data: Dict[str, Any], category: str):
        """L1 Human ìºì‹œì— ì €ì¥"""
        if category == "upper_body":
            l1_cache = self.l1_human_upper
        elif category == "lower_body":
            l1_cache = self.l1_human_lower
        else:
            l1_cache = self.l1_human_dresses

        # ì •í™•í•œ í¬ê¸° ê³„ì‚°
        size_bytes = sum(self._accurate_size(v) for v in data.values())

        entry = CacheEntry(
            key=user_id,
            data=data,
            size_bytes=size_bytes,
            created_at=time.time(),
            accessed_at=time.time(),
            access_count=1,
            base_ttl=self.ttl_seconds,
        )

        l1_cache[user_id] = entry
        l1_cache.move_to_end(user_id)

        # LRU eviction
        self._evict_lru(l1_cache, self.l1_max_users)

    async def get_garment_cache(self, clothing_id: str) -> Optional[Dict[str, Any]]:
        """Garment ìºì‹œ ì¡°íšŒ (ë™ì‹œì„± ì•ˆì „)"""
        cache_key = f"garment_{clothing_id}"

        # L1 ì²´í¬
        if clothing_id in self.l1_garment:
            entry = self.l1_garment[clothing_id]

            if self._is_expired(entry):
                del self.l1_garment[clothing_id]
            else:
                entry.accessed_at = time.time()
                entry.access_count += 1
                self.l1_garment.move_to_end(clothing_id)
                self.stats["l1_hits"] += 1
                logger.info(f"âœ… L1 HIT: garment {clothing_id}")
                return entry.data

        # Cache Stampede ë°©ì§€
        if cache_key in self._loading:
            self.stats["stampede_prevented"] += 1
            for _ in range(60):
                await asyncio.sleep(0.5)
                if cache_key not in self._loading:
                    if clothing_id in self.l1_garment:
                        return self.l1_garment[clothing_id].data
                    break

        lock = self._get_lock(cache_key)
        async with lock:
            if clothing_id in self.l1_garment:
                return self.l1_garment[clothing_id].data

            self._loading.add(cache_key)

            try:
                l2_data = await asyncio.to_thread(
                    self._load_from_ssd, "garment", clothing_id
                )

                if l2_data:
                    self.stats["l2_hits"] += 1
                    logger.info(f"âœ… L2 HIT: garment {clothing_id}")
                    self._put_l1_garment(clothing_id, l2_data)
                    return l2_data

                return None

            finally:
                self._loading.discard(cache_key)

    def put_garment_cache(self, clothing_id: str, data: Dict[str, Any]):
        """Garment ìºì‹œ ì €ì¥"""
        self._put_l1_garment(clothing_id, data)

        try:
            self._save_to_ssd("garment", clothing_id, data)
            logger.info(f"ğŸ’¾ Cached garment {clothing_id} to L1 + L2")
        except Exception as e:
            logger.error(f"âŒ Failed to save to L2: {e}")

    def _put_l1_garment(self, clothing_id: str, data: Dict[str, Any]):
        """L1 Garment ìºì‹œì— ì €ì¥"""
        size_bytes = sum(self._accurate_size(v) for v in data.values())

        entry = CacheEntry(
            key=clothing_id,
            data=data,
            size_bytes=size_bytes,
            created_at=time.time(),
            accessed_at=time.time(),
            access_count=1,
            base_ttl=self.ttl_seconds,
        )

        self.l1_garment[clothing_id] = entry
        self.l1_garment.move_to_end(clothing_id)
        self._evict_lru(self.l1_garment, self.l1_max_garments)

    async def get_text_cache(self, clothing_id: str) -> Optional[Dict[str, Any]]:
        """Text ìºì‹œ ì¡°íšŒ (ë™ì‹œì„± ì•ˆì „)"""
        cache_key = f"text_{clothing_id}"

        if clothing_id in self.l1_text:
            entry = self.l1_text[clothing_id]

            if self._is_expired(entry):
                del self.l1_text[clothing_id]
            else:
                entry.accessed_at = time.time()
                entry.access_count += 1
                self.l1_text.move_to_end(clothing_id)
                self.stats["l1_hits"] += 1
                return entry.data

        if cache_key in self._loading:
            self.stats["stampede_prevented"] += 1
            for _ in range(60):
                await asyncio.sleep(0.5)
                if cache_key not in self._loading:
                    if clothing_id in self.l1_text:
                        return self.l1_text[clothing_id].data
                    break

        lock = self._get_lock(cache_key)
        async with lock:
            if clothing_id in self.l1_text:
                return self.l1_text[clothing_id].data

            self._loading.add(cache_key)

            try:
                l2_data = await asyncio.to_thread(
                    self._load_from_ssd, "text", clothing_id
                )

                if l2_data:
                    self.stats["l2_hits"] += 1
                    self._put_l1_text(clothing_id, l2_data)
                    return l2_data

                return None

            finally:
                self._loading.discard(cache_key)

    def put_text_cache(self, clothing_id: str, data: Dict[str, Any]):
        """Text ìºì‹œ ì €ì¥"""
        self._put_l1_text(clothing_id, data)

        try:
            self._save_to_ssd("text", clothing_id, data)
        except Exception as e:
            logger.error(f"âŒ Failed to save to L2: {e}")

    def _put_l1_text(self, clothing_id: str, data: Dict[str, Any]):
        """L1 Text ìºì‹œì— ì €ì¥"""
        size_bytes = sum(self._accurate_size(v) for v in data.values())

        entry = CacheEntry(
            key=clothing_id,
            data=data,
            size_bytes=size_bytes,
            created_at=time.time(),
            accessed_at=time.time(),
            access_count=1,
            base_ttl=self.ttl_seconds,
        )

        self.l1_text[clothing_id] = entry
        self.l1_text.move_to_end(clothing_id)
        self._evict_lru(self.l1_text, self.l1_max_garments)

    def clear_user_cache(self, user_id: str):
        """íŠ¹ì • ì‚¬ìš©ìì˜ ëª¨ë“  ìºì‹œ ì‚­ì œ"""
        if user_id in self.l1_human_upper:
            del self.l1_human_upper[user_id]
        if user_id in self.l1_human_lower:
            del self.l1_human_lower[user_id]
        if user_id in self.l1_human_dresses:
            del self.l1_human_dresses[user_id]

        for category in ["upper_body", "lower_body", "dresses"]:
            ssd_path = self.ssd_root / f"human_{category}" / user_id
            if ssd_path.exists():
                shutil.rmtree(ssd_path)

        logger.info(f"ğŸ—‘ï¸  Cleared all cache for user {user_id}")

    def clear_garment_cache(self, clothing_id: str):
        """íŠ¹ì • ì˜·ì˜ ìºì‹œ ì‚­ì œ"""
        if clothing_id in self.l1_garment:
            del self.l1_garment[clothing_id]
        if clothing_id in self.l1_text:
            del self.l1_text[clothing_id]

        for cache_type in ["garment", "text"]:
            ssd_path = self.ssd_root / cache_type / clothing_id
            if ssd_path.exists():
                shutil.rmtree(ssd_path)

    def get_stats(self) -> Dict:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        total_requests = (
            self.stats["l1_hits"] +
            self.stats["l2_hits"] +
            self.stats["l3_hits"]
        )

        l1_hit_rate = (
            self.stats["l1_hits"] / total_requests * 100
            if total_requests > 0 else 0
        )
        l2_hit_rate = (
            self.stats["l2_hits"] / total_requests * 100
            if total_requests > 0 else 0
        )

        # L2 ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰
        try:
            disk_usage = sum(
                f.stat().st_size
                for f in self.ssd_root.rglob('*')
                if f.is_file()
            ) / 1024 / 1024 / 1024  # GB
        except:
            disk_usage = 0

        return {
            **self.stats,
            "total_requests": total_requests,
            "l1_hit_rate": round(l1_hit_rate, 2),
            "l2_hit_rate": round(l2_hit_rate, 2),
            "l1_human_upper_count": len(self.l1_human_upper),
            "l1_human_lower_count": len(self.l1_human_lower),
            "l1_human_dresses_count": len(self.l1_human_dresses),
            "l1_garment_count": len(self.l1_garment),
            "l1_text_count": len(self.l1_text),
            "l2_disk_usage_gb": round(disk_usage, 2),
            "l2_disk_limit_gb": round(self.max_disk_bytes / 1024 / 1024 / 1024, 2),
        }

    @staticmethod
    def _accurate_size(obj: Any) -> int:
        """ì •í™•í•œ ê°ì²´ í¬ê¸° ê³„ì‚° (bytes)"""
        if isinstance(obj, torch.Tensor):
            return obj.element_size() * obj.nelement()
        elif isinstance(obj, Image.Image):
            # PIL Imageì˜ ì‹¤ì œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            return len(obj.tobytes())
        else:
            # sys.getsizeofë¡œ ì •í™•í•œ í¬ê¸° ê³„ì‚°
            return sys.getsizeof(obj)
